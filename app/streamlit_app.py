import os
import pandas as pd
import numpy as np
import re
import pickle
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import streamlit as st
from matplotlib import font_manager, rc

# âœ… ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_PATH = os.path.join(BASE_DIR, "..", "data", "preprocessed_labeled.csv")
MODEL_PATH = os.path.join(BASE_DIR, "..", "model", "sentiment_model.keras")
TOKENIZER_PATH = os.path.join(BASE_DIR, "..", "model", "tokenizer.pkl")
FONT_PATH = os.path.join(BASE_DIR, "..", "data", "NanumGothic.ttf")

# âœ… í•œê¸€ í°íŠ¸ ì„¤ì •
font_name = font_manager.FontProperties(fname=FONT_PATH).get_name()
rc('font', family=font_name)
plt.rcParams['font.family'] = font_name

# âœ… Streamlit UI ì„¤ì •
st.set_page_config(page_title="Real Estate Sentiment", layout="centered")
st.title("ğŸ“Š ë¶€ë™ì‚° ë‰´ìŠ¤ ê°ì • ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# âœ… ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_resource
def load_resources():
    model = load_model(MODEL_PATH)
    with open(TOKENIZER_PATH, "rb") as f:
        tokenizer = pickle.load(f)
    return model, tokenizer

model, tokenizer = load_resources()

# âœ… ë¶ˆìš©ì–´ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
stopwords = ["ì˜", "ê°€", "ì´", "ì€", "ë“¤", "ëŠ”", "ì¢€", "ì˜", "ê±", "ê³¼", "ë„", "ë¥¼", "ìœ¼ë¡œ", "ì", "ì—", "ì™€", "í•œ", "í•˜ë‹¤"]

def clean_text(text):
    text = re.sub(r"[^ê°€-í£0-9\s]", "", str(text))
    return re.sub(r"\s+", " ", text).strip()

def tokenize(text):
    return [word for word in clean_text(text).split() if word not in stopwords]

def preprocess(text):
    tokens = tokenize(text)
    seq = tokenizer.texts_to_sequences([" ".join(tokens)])
    return pad_sequences(seq, maxlen=30)

# âœ… ë°ì´í„° ë¡œë”©
@st.cache_data
def load_dataframe():
    if os.path.exists(DATA_PATH):
        df = pd.read_csv(DATA_PATH)
        return df.dropna(subset=["clean_title", "label"])
    return pd.DataFrame(columns=["clean_title", "label"])

if "df" not in st.session_state:
    st.session_state.df = load_dataframe()

df = st.session_state.df

# âœ… ìˆ˜ë™ ìƒ˜í”Œ ì¶”ê°€
manual = pd.DataFrame([
    {"clean_title": "ì„œìš¸ ì•„íŒŒíŠ¸ ë¶„ì–‘ ì™„íŒ, ì‹¤ìˆ˜ìš”ì ëª°ë ¤", "label": 1},
    {"clean_title": "ì •ë¶€ ë¶€ë™ì‚° ëŒ€ì±… íš¨ê³¼ ê¸°ëŒ€", "label": 1},
    {"clean_title": "ì „ì„¸ ì‚¬ê¸° í”¼í•´ì ì†ì¶œ, ë¶€ë™ì‚° ì‹œì¥ ë¶ˆì‹ ", "label": 0},
    {"clean_title": "ì§‘ê°’ í•˜ë½ì„¸ ì§€ì†, íˆ¬ììë“¤ ì†ì‹¤ ìš°ë ¤", "label": 0}
])
df = pd.concat([df, manual], ignore_index=True)

# âœ… ê°ì • ë¶„í¬ ì‹œê°í™” (ì˜ë¬¸ ë¼ë²¨)
st.subheader("ğŸ“Œ Sentiment Distribution")
label_counts = Counter(df["label"])
full_counts = [label_counts.get(i, 0) for i in range(3)]
fig, ax = plt.subplots()
colors = ['#FF6B6B', '#4ECDC4', '#1A535C']
ax.pie(full_counts, labels=["Negative", "Positive", "Neutral"], colors=colors, autopct="%.1f%%", startangle=90)
ax.axis("equal")
st.pyplot(fig)

# âœ… ê¸ì • ë‰´ìŠ¤ ì›Œë“œí´ë¼ìš°ë“œ
st.subheader("ğŸ“Œ Word Cloud (Positive News)")
if df[df["label"] == 1].shape[0] > 0:
    positive_text = " ".join(df[df["label"] == 1]["clean_title"])
    wc = WordCloud(font_path=FONT_PATH, background_color="white").generate(positive_text)
    st.image(wc.to_array(), use_container_width=True)
else:
    st.info("ê¸ì • ë‰´ìŠ¤ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

# âœ… ì‚¬ìš©ì ì…ë ¥ ê°ì • ì˜ˆì¸¡
st.subheader("ğŸ§  Predict Sentiment from News Title")
user_input = st.text_input("ë‰´ìŠ¤ ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”:", key="sentiment_input")

if user_input:
    tokens = tokenize(user_input)
    oov_count = sum(1 for word in tokens if word not in tokenizer.word_index)
    oov_ratio = oov_count / len(tokens) if tokens else 0

    if oov_ratio > 0.5:
        st.warning("âš ï¸ ì…ë ¥í•˜ì‹  ë¬¸ì¥ì— í•™ìŠµë˜ì§€ ì•Šì€ ë‹¨ì–´ê°€ ë§ì•„ ì˜ˆì¸¡ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif oov_ratio > 0:
        st.info(f"â„¹ï¸ ì…ë ¥ì— {oov_count}ê°œì˜ OOV ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    x_input = preprocess(user_input)
    pred = model.predict(x_input)
    label = np.argmax(pred)
    label_text = {0: "Negative", 1: "Positive", 2: "Neutral"}[label]
    st.success(f"âœ… ì˜ˆì¸¡ëœ ê°ì •: {label_text}")
    st.markdown(f"ğŸ“Š ì˜ˆì¸¡ í™•ë¥ : `{[round(float(p), 3) for p in pred[0]]}`")

    new_row = pd.DataFrame([{"clean_title": user_input, "label": label}])
    st.session_state.df = pd.concat([st.session_state.df, new_row], ignore_index=True)
